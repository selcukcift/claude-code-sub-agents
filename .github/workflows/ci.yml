# TORVAN MEDICAL DEVICE CI/CD PIPELINE
# ====================================
# 
# Comprehensive Continuous Integration pipeline for medical device software
# Implements quality gates, security scanning, and compliance validation
# Supports FDA 21 CFR Part 820 and ISO 13485 requirements

name: Continuous Integration

on:
  push:
    branches: [ main, develop, feature/*, release/*, hotfix/* ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:
    inputs:
      skip_tests:
        description: 'Skip test execution (emergency only)'
        required: false
        default: 'false'
        type: choice
        options:
          - 'false'
          - 'true'

env:
  NODE_VERSION: '20'
  POSTGRES_VERSION: '15'
  DATABASE_URL: 'postgresql://torvan_user:torvan_pass@localhost:5432/torvan_ci'
  TEST_DATABASE_URL: 'postgresql://torvan_user:torvan_pass@localhost:5432/torvan_test'
  NEXTAUTH_URL: 'http://localhost:3000'
  NEXTAUTH_SECRET: ${{ secrets.NEXTAUTH_SECRET || 'development-secret-key' }}
  CI: true

# Concurrency control to prevent multiple runs
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # Pre-flight checks and setup
  pre-flight:
    name: Pre-flight Checks
    runs-on: ubuntu-latest
    outputs:
      should-run-tests: ${{ steps.check-conditions.outputs.should-run-tests }}
      node-cache-key: ${{ steps.cache-key.outputs.node-cache-key }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # Full history for better analysis

      - name: Check conditions
        id: check-conditions
        run: |
          if [ "${{ github.event.inputs.skip_tests }}" = "true" ]; then
            echo "should-run-tests=false" >> $GITHUB_OUTPUT
            echo "âš ï¸ Tests will be skipped due to manual override"
          else
            echo "should-run-tests=true" >> $GITHUB_OUTPUT
          fi

      - name: Generate cache key
        id: cache-key
        run: |
          echo "node-cache-key=node-${{ env.NODE_VERSION }}-${{ hashFiles('**/package-lock.json') }}" >> $GITHUB_OUTPUT

      - name: Validate package.json
        run: |
          if [ ! -f "package.json" ]; then
            echo "âŒ package.json not found"
            exit 1
          fi
          npm pkg validate
          echo "âœ… package.json is valid"

  # Code Quality and Standards
  code-quality:
    name: Code Quality Analysis
    runs-on: ubuntu-latest
    needs: pre-flight
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci --prefer-offline

      - name: TypeScript compilation check
        run: |
          echo "ðŸ” Running TypeScript compilation check..."
          npm run type-check
          echo "âœ… TypeScript compilation successful"

      - name: ESLint analysis
        run: |
          echo "ðŸ” Running ESLint analysis..."
          npm run lint -- --format=json --output-file=eslint-report.json || true
          npm run lint
          echo "âœ… ESLint analysis completed"

      - name: Prettier formatting check
        run: |
          echo "ðŸ” Checking code formatting..."
          npm run format:check
          echo "âœ… Code formatting is correct"

      - name: Dead code detection
        run: |
          echo "ðŸ” Scanning for dead code..."
          npx ts-unused-exports tsconfig.json --ignoreFiles='**/*.test.ts,**/*.test.tsx,**/*.spec.ts'
          echo "âœ… Dead code scan completed"

      - name: Upload code quality artifacts
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: code-quality-reports
          path: |
            eslint-report.json
            *.log

  # Dependency Security Analysis  
  dependency-security:
    name: Dependency Security Scan
    runs-on: ubuntu-latest
    needs: pre-flight
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci --prefer-offline

      - name: NPM Security Audit
        run: |
          echo "ðŸ” Running NPM security audit..."
          npm audit --audit-level=moderate --json > npm-audit.json || true
          npm audit --audit-level=moderate
          echo "âœ… NPM security audit completed"

      - name: License compliance check
        run: |
          echo "ðŸ” Checking license compliance..."
          npx license-checker \
            --onlyAllow 'MIT;Apache-2.0;BSD-2-Clause;BSD-3-Clause;ISC;CC0-1.0;Unlicense' \
            --excludePrivatePackages \
            --json > license-report.json
          echo "âœ… License compliance verified"

      - name: Check for known vulnerabilities
        uses: snyk/actions/node@master
        continue-on-error: true
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
        with:
          args: --severity-threshold=high --json-file-output=snyk-report.json

      - name: Upload security artifacts
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: security-reports
          path: |
            npm-audit.json
            license-report.json
            snyk-report.json

  # Unit Testing
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    needs: [pre-flight, code-quality]
    if: needs.pre-flight.outputs.should-run-tests == 'true'
    strategy:
      matrix:
        test-group: [auth, components, database, security, utils]
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci --prefer-offline

      - name: Generate Prisma client
        run: npm run db:generate

      - name: Run unit tests for ${{ matrix.test-group }}
        run: |
          echo "ðŸ§ª Running unit tests for ${{ matrix.test-group }}..."
          npm run test:unit -- \
            --testPathPattern="${{ matrix.test-group }}" \
            --coverage \
            --coverageDirectory="coverage/unit-${{ matrix.test-group }}" \
            --coverageReporters=lcov,json \
            --maxWorkers=2 \
            --verbose

      - name: Upload unit test coverage
        uses: codecov/codecov-action@v3
        with:
          files: coverage/unit-${{ matrix.test-group }}/lcov.info
          flags: unit-tests,${{ matrix.test-group }}
          name: unit-${{ matrix.test-group }}-coverage

      - name: Upload test artifacts
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: unit-test-results-${{ matrix.test-group }}
          path: |
            coverage/unit-${{ matrix.test-group }}/
            test-results/unit/

  # Integration Testing
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: [pre-flight, code-quality]
    if: needs.pre-flight.outputs.should-run-tests == 'true'
    services:
      postgres:
        image: postgres:${{ env.POSTGRES_VERSION }}
        env:
          POSTGRES_USER: torvan_user
          POSTGRES_PASSWORD: torvan_pass
          POSTGRES_DB: torvan_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
          --shm-size=256mb
        ports:
          - 5432:5432

      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci --prefer-offline

      - name: Wait for PostgreSQL
        run: |
          timeout 30 bash -c 'until pg_isready -h localhost -p 5432 -U torvan_user; do sleep 1; done'

      - name: Setup test database
        run: |
          echo "ðŸ—„ï¸ Setting up test database..."
          npm run db:push
          npm run db:seed
          echo "âœ… Database setup completed"

      - name: Run integration tests
        run: |
          echo "ðŸ”— Running integration tests..."
          npm run test:integration -- \
            --coverage \
            --coverageDirectory="coverage/integration" \
            --coverageReporters=lcov,json \
            --maxWorkers=2 \
            --verbose \
            --forceExit

      - name: Upload integration test coverage
        uses: codecov/codecov-action@v3
        with:
          files: coverage/integration/lcov.info
          flags: integration-tests
          name: integration-coverage

      - name: Upload integration test artifacts
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: integration-test-results
          path: |
            coverage/integration/
            test-results/integration/

  # Security Testing
  security-tests:
    name: Security Tests
    runs-on: ubuntu-latest
    needs: [pre-flight, code-quality]
    if: needs.pre-flight.outputs.should-run-tests == 'true'
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci --prefer-offline

      - name: Run security tests
        run: |
          echo "ðŸ”’ Running security tests..."
          npm run test:security -- \
            --coverage \
            --coverageDirectory="coverage/security" \
            --coverageReporters=lcov,json \
            --verbose

      - name: SAST Security Scan
        uses: github/super-linter@v4
        env:
          DEFAULT_BRANCH: main
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          VALIDATE_TYPESCRIPT_ES: true
          VALIDATE_JAVASCRIPT_ES: true
          VALIDATE_JSON: true
          VALIDATE_YAML: true
          VALIDATE_DOCKERFILE: true

      - name: Upload security test artifacts
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: security-test-results
          path: |
            coverage/security/
            test-results/security/
            super-linter.log

  # Performance Testing
  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    needs: [pre-flight, unit-tests]
    if: needs.pre-flight.outputs.should-run-tests == 'true'
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci --prefer-offline

      - name: Run performance tests
        run: |
          echo "âš¡ Running performance tests..."
          npm run test:performance -- \
            --coverage \
            --coverageDirectory="coverage/performance" \
            --coverageReporters=lcov,json \
            --verbose

      - name: BOM Generation Performance Validation
        run: |
          echo "ðŸ“Š Validating BOM generation performance..."
          npm run test:performance -- \
            --testNamePattern="BOM generation" \
            --verbose \
            --testTimeout=6000
          
          if [ $? -ne 0 ]; then
            echo "âŒ BOM generation performance test failed"
            echo "Requirements: BOM generation must complete within 5 seconds"
            exit 1
          fi
          echo "âœ… BOM generation performance validated"

      - name: Page Load Performance Test
        run: |
          echo "ðŸ“„ Testing page load performance..."
          npm run build
          npm run start &
          SERVER_PID=$!
          
          sleep 10 # Wait for server to start
          
          # Use curl to test page load times
          for endpoint in "/" "/auth/signin" "/dashboard"; do
            echo "Testing $endpoint..."
            response_time=$(curl -o /dev/null -s -w '%{time_total}' http://localhost:3000$endpoint)
            if (( $(echo "$response_time > 3.0" | bc -l) )); then
              echo "âŒ Page $endpoint load time: ${response_time}s exceeds 3s requirement"
              kill $SERVER_PID
              exit 1
            fi
            echo "âœ… Page $endpoint load time: ${response_time}s"
          done
          
          kill $SERVER_PID

      - name: Upload performance test artifacts
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: performance-test-results
          path: |
            coverage/performance/
            test-results/performance/

  # Medical Device Compliance Testing
  medical-compliance:
    name: Medical Device Compliance
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, security-tests]
    if: needs.pre-flight.outputs.should-run-tests == 'true'
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci --prefer-offline

      - name: FDA 21 CFR Part 820 Compliance Tests
        run: |
          echo "ðŸ¥ Running FDA 21 CFR Part 820 compliance tests..."
          npm run test:medical-compliance -- \
            --testPathPattern="fda" \
            --verbose \
            --reporters=default \
            --reporters=jest-html-reporters

      - name: ISO 13485 Compliance Tests
        run: |
          echo "ðŸ“‹ Running ISO 13485 compliance tests..."
          npm run test:medical-compliance -- \
            --testPathPattern="iso" \
            --verbose \
            --reporters=default \
            --reporters=jest-html-reporters

      - name: IEC 62304 Software Lifecycle Compliance
        run: |
          echo "âš•ï¸ Running IEC 62304 compliance tests..."
          npm run test:medical-compliance -- \
            --testPathPattern="iec" \
            --verbose \
            --reporters=default \
            --reporters=jest-html-reporters

      - name: Generate compliance documentation
        run: |
          echo "ðŸ“ Generating compliance documentation..."
          cat > compliance-summary.md << EOF
          # Medical Device Compliance Summary
          
          **Generated:** $(date -u +"%Y-%m-%d %H:%M:%S UTC")
          **Commit:** ${{ github.sha }}
          **Branch:** ${{ github.ref_name }}
          
          ## Regulatory Compliance Status
          
          ### FDA 21 CFR Part 820 - Quality System Regulation
          - âœ… Design Controls (820.30)
          - âœ… Document Controls (820.40)
          - âœ… Management Responsibility (820.20)
          - âœ… Risk Management (820.30)
          
          ### ISO 13485:2016 - Medical Device Quality Management
          - âœ… Quality Management System (Clause 4)
          - âœ… Management Responsibility (Clause 5)
          - âœ… Resource Management (Clause 6)
          - âœ… Product Realization (Clause 7)
          - âœ… Measurement and Improvement (Clause 8)
          
          ### IEC 62304:2006 - Medical Device Software Lifecycle
          - âœ… Software Development Planning (Clause 5)
          - âœ… Software Requirements Analysis (Clause 5.2)
          - âœ… Software Verification and Validation (Clause 5.6)
          - âœ… Risk Management (Clause 7)
          
          ## Test Coverage
          - Unit Tests: Target >85%
          - Integration Tests: Target >80%
          - Security Tests: 100% (Critical Components)
          - Performance Tests: All benchmarks met
          
          ## Audit Trail
          All changes tracked via Git with:
          - Developer identification
          - Change timestamps
          - Change descriptions
          - Review approvals
          EOF

      - name: Upload compliance artifacts
        uses: actions/upload-artifact@v3
        with:
          name: medical-compliance-reports
          path: |
            test-results/medical-compliance/
            compliance-summary.md
            test-results/html/

  # Build and Package Validation
  build-validation:
    name: Build Validation
    runs-on: ubuntu-latest
    needs: [code-quality, dependency-security]
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci --prefer-offline

      - name: Generate Prisma client
        run: npm run db:generate

      - name: Build application
        run: |
          echo "ðŸ—ï¸ Building application..."
          npm run build
          echo "âœ… Build completed successfully"

      - name: Validate build artifacts
        run: |
          echo "ðŸ” Validating build artifacts..."
          
          if [ ! -d ".next" ]; then
            echo "âŒ Build directory (.next) not found"
            exit 1
          fi
          
          if [ ! -f ".next/BUILD_ID" ]; then
            echo "âŒ Build ID file not found"
            exit 1
          fi
          
          # Check for critical build files
          required_files=(".next/server/app" ".next/static")
          for file in "${required_files[@]}"; do
            if [ ! -e "$file" ]; then
              echo "âŒ Required build artifact missing: $file"
              exit 1
            fi
          done
          
          echo "âœ… All build artifacts validated"

      - name: Bundle size analysis
        run: |
          echo "ðŸ“¦ Analyzing bundle size..."
          npm run build:analyze
          
          # Check bundle size limits (example thresholds)
          bundle_size=$(du -sb .next | cut -f1)
          max_size=$((50 * 1024 * 1024)) # 50MB limit
          
          if [ $bundle_size -gt $max_size ]; then
            echo "âš ï¸ Bundle size ($bundle_size bytes) exceeds limit ($max_size bytes)"
            # Don't fail build, just warn
          else
            echo "âœ… Bundle size within limits: $bundle_size bytes"
          fi

      - name: Security scan of build artifacts
        run: |
          echo "ðŸ”’ Scanning build artifacts for security issues..."
          
          # Check for sensitive information in build
          if grep -r "password\|secret\|key" .next/ --include="*.js" --include="*.json" | grep -v "publicKey\|keyCode"; then
            echo "âš ï¸ Potential sensitive information found in build artifacts"
            echo "Please review the above matches"
          else
            echo "âœ… No sensitive information detected in build"
          fi

      - name: Upload build artifacts
        uses: actions/upload-artifact@v3
        with:
          name: build-artifacts
          path: |
            .next/
            dist/
          retention-days: 30

  # Test Coverage Analysis
  coverage-analysis:
    name: Coverage Analysis
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, security-tests, performance-tests]
    if: always() && needs.pre-flight.outputs.should-run-tests == 'true'
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download all coverage artifacts
        uses: actions/download-artifact@v3
        with:
          path: coverage-artifacts/

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci --prefer-offline

      - name: Merge coverage reports
        run: |
          echo "ðŸ“Š Merging coverage reports..."
          
          # Install coverage merging tools
          npm install -g nyc
          
          # Merge all coverage files
          find coverage-artifacts/ -name "lcov.info" -exec cat {} \; > merged-coverage.info
          
          # Generate comprehensive coverage report
          npm run test:coverage -- --coverageReporters=html --coverageReporters=text --coverageReporters=cobertura

      - name: Coverage threshold validation
        run: |
          echo "ðŸ“ˆ Validating coverage thresholds..."
          
          # Medical device critical components require higher coverage
          npm run test:coverage -- \
            --coverageThreshold='{
              "global": {
                "branches": 85,
                "functions": 85,
                "lines": 85,
                "statements": 85
              },
              "src/lib/security/**/*.ts": {
                "branches": 100,
                "functions": 100,
                "lines": 100,
                "statements": 100
              },
              "src/lib/auth.ts": {
                "branches": 95,
                "functions": 95,
                "lines": 95,
                "statements": 95
              }
            }' \
            --passWithNoTests

      - name: Generate coverage summary
        run: |
          echo "ðŸ“‹ Generating coverage summary..."
          
          cat > coverage-summary.md << EOF
          # Test Coverage Summary
          
          **Generated:** $(date -u +"%Y-%m-%d %H:%M:%S UTC")
          **Commit:** ${{ github.sha }}
          **Branch:** ${{ github.ref_name }}
          
          ## Coverage Requirements
          
          ### Global Thresholds (85% minimum)
          - Lines: 85%
          - Functions: 85%
          - Branches: 85%
          - Statements: 85%
          
          ### Critical Component Thresholds (100% required)
          - Security modules: 100%
          - Authentication: 95%
          - Medical device core functions: 100%
          
          ## Test Categories
          - Unit Tests: Component and function level testing
          - Integration Tests: API and workflow testing
          - Security Tests: Authentication and authorization
          - Performance Tests: Load and response time validation
          - Medical Compliance Tests: Regulatory requirement validation
          
          ## Quality Gates Status
          $(if [ -f "coverage/lcov-report/index.html" ]; then echo "âœ… Coverage reports generated"; else echo "âŒ Coverage report generation failed"; fi)
          EOF

      - name: Upload comprehensive coverage
        uses: codecov/codecov-action@v3
        with:
          files: merged-coverage.info,coverage/lcov.info
          flags: comprehensive
          name: comprehensive-coverage

      - name: Comment PR with coverage
        if: github.event_name == 'pull_request'
        uses: romeovs/lcov-reporter-action@v0.3.1
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          lcov-file: merged-coverage.info
          delete-old-comments: true

      - name: Upload coverage artifacts
        uses: actions/upload-artifact@v3
        with:
          name: comprehensive-coverage-report
          path: |
            coverage/
            coverage-summary.md
            merged-coverage.info

  # Final Quality Gate
  quality-gate:
    name: Quality Gate Assessment
    runs-on: ubuntu-latest
    needs: [
      build-validation,
      coverage-analysis,
      medical-compliance,
      performance-tests
    ]
    if: always()
    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v3

      - name: Assess quality gate status
        run: |
          echo "ðŸšª Assessing quality gate status..."
          
          # Check if all required jobs passed
          exit_code=0
          
          if [ "${{ needs.build-validation.result }}" != "success" ]; then
            echo "âŒ Build validation failed"
            exit_code=1
          else
            echo "âœ… Build validation passed"
          fi
          
          if [ "${{ needs.coverage-analysis.result }}" != "success" ]; then
            echo "âŒ Coverage analysis failed"
            exit_code=1
          else
            echo "âœ… Coverage analysis passed"
          fi
          
          if [ "${{ needs.medical-compliance.result }}" != "success" ]; then
            echo "âŒ Medical compliance validation failed"
            exit_code=1
          else
            echo "âœ… Medical compliance validated"
          fi
          
          if [ "${{ needs.performance-tests.result }}" != "success" ]; then
            echo "âŒ Performance tests failed"
            exit_code=1
          else
            echo "âœ… Performance tests passed"
          fi
          
          if [ $exit_code -eq 0 ]; then
            echo ""
            echo "ðŸŽ‰ ALL QUALITY GATES PASSED"
            echo "âœ… Code ready for deployment"
            echo ""
            echo "Summary:"
            echo "- Build: âœ… Successful"
            echo "- Tests: âœ… All passed"
            echo "- Coverage: âœ… Meets thresholds"
            echo "- Security: âœ… Validated"
            echo "- Performance: âœ… Benchmarks met"
            echo "- Medical Compliance: âœ… FDA/ISO validated"
          else
            echo ""
            echo "âŒ QUALITY GATE FAILED"
            echo "Review failed checks before proceeding"
          fi
          
          exit $exit_code

      - name: Generate quality gate report
        if: always()
        run: |
          cat > quality-gate-report.md << EOF
          # Quality Gate Assessment Report
          
          **Generated:** $(date -u +"%Y-%m-%d %H:%M:%S UTC")
          **Commit:** ${{ github.sha }}
          **Branch:** ${{ github.ref_name }}
          **Workflow:** ${{ github.workflow }}
          **Run ID:** ${{ github.run_id }}
          
          ## Quality Gate Results
          
          | Check | Status | Details |
          |-------|--------|---------|
          | Build Validation | ${{ needs.build-validation.result == 'success' && 'âœ… PASSED' || 'âŒ FAILED' }} | Application build and artifact validation |
          | Coverage Analysis | ${{ needs.coverage-analysis.result == 'success' && 'âœ… PASSED' || 'âŒ FAILED' }} | Test coverage meets 85% threshold |
          | Medical Compliance | ${{ needs.medical-compliance.result == 'success' && 'âœ… PASSED' || 'âŒ FAILED' }} | FDA/ISO/IEC regulatory compliance |
          | Performance Tests | ${{ needs.performance-tests.result == 'success' && 'âœ… PASSED' || 'âŒ FAILED' }} | Performance benchmarks validated |
          
          ## Medical Device Compliance Status
          - FDA 21 CFR Part 820: ${{ needs.medical-compliance.result == 'success' && 'âœ… COMPLIANT' || 'âŒ NON-COMPLIANT' }}
          - ISO 13485:2016: ${{ needs.medical-compliance.result == 'success' && 'âœ… COMPLIANT' || 'âŒ NON-COMPLIANT' }}
          - IEC 62304:2006: ${{ needs.medical-compliance.result == 'success' && 'âœ… COMPLIANT' || 'âŒ NON-COMPLIANT' }}
          
          ## Deployment Readiness
          ${{ (needs.build-validation.result == 'success' && needs.coverage-analysis.result == 'success' && needs.medical-compliance.result == 'success' && needs.performance-tests.result == 'success') && 'âœ… APPROVED FOR DEPLOYMENT' || 'âŒ NOT APPROVED - Review failed checks' }}
          
          ## Next Steps
          ${{ (needs.build-validation.result == 'success' && needs.coverage-analysis.result == 'success' && needs.medical-compliance.result == 'success' && needs.performance-tests.result == 'success') && '- Proceed with deployment workflow\n- Monitor post-deployment metrics\n- Update compliance documentation' || '- Review and fix failed quality checks\n- Re-run pipeline after fixes\n- Ensure all medical device requirements are met' }}
          EOF

      - name: Upload quality gate report
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: quality-gate-report
          path: quality-gate-report.md

  # Notification
  notify:
    name: Pipeline Notification
    runs-on: ubuntu-latest
    needs: [quality-gate]
    if: always()
    steps:
      - name: Notify pipeline completion
        run: |
          if [ "${{ needs.quality-gate.result }}" == "success" ]; then
            echo "ðŸŽ‰ TORVAN CI Pipeline: SUCCESS"
            echo "All quality gates passed - ready for deployment"
          else
            echo "âŒ TORVAN CI Pipeline: FAILED"
            echo "Quality gates failed - review required before deployment"
          fi
          
          echo ""
          echo "Pipeline Summary:"
          echo "- Repository: ${{ github.repository }}"
          echo "- Branch: ${{ github.ref_name }}"
          echo "- Commit: ${{ github.sha }}"
          echo "- Workflow: ${{ github.workflow }}"
          echo "- Run ID: ${{ github.run_id }}"
          echo "- Trigger: ${{ github.event_name }}"